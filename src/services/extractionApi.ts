/**
 * DATA SCIENCE APPROACH TO INSURANCE POLICY EXTRACTION
 * 
 * This module implements a comprehensive data science strategy for extracting
 * insurance policy data with maximum accuracy. Key improvements:
 * 
 * 1. MULTI-MODEL STRATEGY
 *    - Primary: o1-preview (superior reasoning for complex documents)
 *    - Fallback: gpt-4o (reliability and speed)
 *    - Automatic fallback on failure
 * 
 * 2. FEW-SHOT LEARNING
 *    - Concrete examples guide the model
 *    - Shows correct extraction patterns
 *    - Demonstrates edge cases (& vs and, missing fields)
 * 
 * 3. TRIPLE-PASS VALIDATION
 *    - Pass 1: Initial extraction
 *    - Pass 2: Revalidation and improvement
 *    - Pass 3: Final cross-check
 * 
 * 4. FIELD-BY-FIELD EXTRACTION (Optional)
 *    - Individual extraction for missing critical fields
 *    - Higher accuracy but slower
 *    - Enable via EXTRACTION_CONFIG.FIELD_BY_FIELD_MODE
 * 
 * 5. CONFIDENCE SCORING
 *    - Each field extraction has confidence score
 *    - Only accept values above threshold
 *    - Track extraction source for debugging
 * 
 * 6. STRUCTURED OUTPUTS
 *    - JSON schema enforcement for consistency
 *    - Prevents parsing errors
 * 
 * 7. COMPREHENSIVE TABLE SEARCH
 *    - Systematic scanning of ALL tables
 *    - Field name variations (& vs and, case-insensitive)
 *    - Special table detection (Provider Specific, etc.)
 * 
 * 8. RETRY LOGIC
 *    - Automatic retries on failure
 *    - Model fallback strategy
 */

//  OpenAI extraction service - SIMPLIFIED VERSION
// Using pdfjs-dist for text extraction + direct OpenAI API calls
import { FIELD_MAPPINGS, PAYER_PLANS, type PayerPlan, type ExtractedData, type ComparisonResult } from "@/constants/fields";
import { FIELD_SUGGESTIONS } from "@/constants/fields";
import { logExtraction } from "@/utils/logging";
// @ts-ignore - pdfjs-dist has type issues with ESM
import * as pdfjsLib from 'pdfjs-dist';

// Set worker path for pdfjs
pdfjsLib.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`;

declare global {
  interface Window {
    gtag: (...args: any[]) => void;
    dataLayer: any[];
  }
}

// Track extraction event in GA4
function trackExtractionEvent(
  eventName: string,
  params: Record<string, any>
) {
  if (typeof window !== 'undefined' && typeof window.gtag === 'function') {
    window.gtag('event', eventName, {
      ...params,
      event_category: 'LLM Extraction',
      non_interaction: false,
    });
  }
}

const OPENAI_BASE = "https://api.openai.com/v1";
const OPENAI_RESPONSES_ENDPOINT = `${OPENAI_BASE}/responses`;
const OPENAI_CHAT_ENDPOINT = `${OPENAI_BASE}/chat/completions`;

// Model configuration - data science approach: use best model for reasoning
const EXTRACTION_CONFIG = {
  // gpt-5 has better reasoning for complex document analysis
  PRIMARY_MODEL: "gpt-5-mini",          // Best for complex reasoning and field extraction
  FALLBACK_MODEL: "gpt-5",         // Fallback model
  MARKDOWN_MODEL: "gpt-5",         // Good for PDF to markdown conversion
  USE_STRUCTURED_OUTPUT: true,     // Force JSON schema for consistency
  FIELD_BY_FIELD_MODE: false,      // Extract fields individually (slower but more accurate)
  MAX_RETRIES: 2,                  // Retry failed extractions
  CONFIDENCE_THRESHOLD: 0.7,       // Minimum confidence for accepting a value
  
  // ADVANCED METHODS (Clever techniques for large PDFs)
  USE_CHUNKED_EXTRACTION: true,    // Process large PDFs in overlapping chunks
  CHUNK_SIZE: 8000,                 // Characters per chunk (with overlap)
  CHUNK_OVERLAP: 1000,              // Overlap between chunks to not miss boundaries
  USE_TABLE_FIRST_EXTRACTION: true, // Extract and parse tables separately first
  USE_SEMANTIC_SEARCH: false,       // Use embeddings to find relevant sections (requires embeddings API)
  USE_REGEX_VALIDATION: true,       // Validate extracted values with regex patterns
  USE_CROSS_VALIDATION: true,       // Cross-check values for logical consistency
  EXTRACT_DOCUMENT_STRUCTURE: true  // First map document structure, then extract
};

function assertKey(apiKey?: string) {
  if (!apiKey) throw new Error("Missing OpenAI API key");
}

/**
 * Helper function to call GPT-5 using the /v1/responses endpoint
 * Falls back to chat/completions if responses endpoint is not available
 */
async function callGPT5Responses(params: {
  apiKey: string;
  userPrompt: string;
  systemPrompt?: string;
  responseFormat?: 'text' | 'json_object';
}): Promise<any> {
  const { apiKey, userPrompt, systemPrompt, responseFormat = 'text' } = params;

  // Try Responses API first
  try {
    // Combine system and user prompts
    const combinedPrompt = systemPrompt 
      ? `${systemPrompt}\n\n${userPrompt}`
      : userPrompt;

    // Build request body for Responses API
    const body: any = {
      model: "gpt-5",
      input: [
        {
          role: "user",
          content: [
            {
              type: "input_text",
              text: combinedPrompt
            }
          ]
        }
      ]
    };

    // Set response format if needed
    if (responseFormat === 'json_object') {
      body.text = {
        format: {
          type: "json_object"
        }
      };
    }

    console.log('[GPT-5 Responses API] Trying Responses API endpoint:', OPENAI_RESPONSES_ENDPOINT);

    const response = await fetch(OPENAI_RESPONSES_ENDPOINT, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(body),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.warn('[GPT-5 Responses API] Responses API failed, will try Chat Completions fallback:', response.status, errorText);
      throw new Error(`Responses API not available: ${response.status}`);
    }

    const data = await response.json();
    console.log('[GPT-5 Responses API] Success! Response received');
    
    // Try multiple paths to extract content from response
    let content = null;
    
    // Try Responses API format - look for message type output with text
    if (data.output && Array.isArray(data.output)) {
      // Find the message type output (not reasoning)
      const messageOutput = data.output.find((item: any) => item.type === 'message');
      if (messageOutput?.content?.[0]?.text) {
        content = messageOutput.content[0].text;
        console.log('[GPT-5 Responses API] Extracted from message output');
      }
    }
    
    // Fallback: Try other formats
    if (!content && data.choices?.[0]?.message?.content) {
      content = data.choices[0].message.content;
      console.log('[GPT-5 Responses API] Extracted from choices format');
    }
    
    if (!content && data.text) {
      content = data.text;
      console.log('[GPT-5 Responses API] Extracted from text field');
    }
    
    if (!content) {
      console.error('[GPT-5 Responses API] Could not extract content from response:', data);
      throw new Error('No content found in GPT-5 Responses API response');
    }
    
    // Ensure content is a string
    if (typeof content !== 'string') {
      console.warn('[GPT-5 Responses API] Content is not a string, converting...', typeof content);
      content = String(content);
    }
    
    console.log('[GPT-5 Responses API] Successfully extracted content, type:', typeof content, 'length:', content.length);
    
    return {
      content,
      raw: data
    };
    
  } catch (responsesApiError) {
    // Fallback to standard Chat Completions API
    console.warn('[GPT-5] Responses API failed, falling back to Chat Completions API');
    console.log('[GPT-5] Fallback error was:', responsesApiError);
    
    const messages: any[] = [];
    if (systemPrompt) {
      messages.push({
        role: "system",
        content: systemPrompt
      });
    }
    messages.push({
      role: "user",
      content: userPrompt
    });

    const body: any = {
      model: "gpt-5",
      messages: messages
    };

    // Add response format for JSON if needed
    if (responseFormat === 'json_object') {
      body.response_format = { type: "json_object" };
    }

    console.log('[GPT-5 Chat Completions] Calling endpoint:', OPENAI_CHAT_ENDPOINT);

    const response = await fetch(OPENAI_CHAT_ENDPOINT, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify(body),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[GPT-5 Chat Completions] Error response:', errorText);
      throw new Error(`GPT-5 Chat Completions API error: ${response.status} ${errorText}`);
    }

    const data = await response.json();
    console.log('[GPT-5 Chat Completions] Response received');
    
    const content = data.choices?.[0]?.message?.content;
    
    if (!content) {
      console.error('[GPT-5 Chat Completions] Could not extract content from response:', data);
      throw new Error('No content found in GPT-5 Chat Completions API response');
    }
    
    // Ensure content is a string
    if (typeof content !== 'string') {
      console.warn('[GPT-5 Chat Completions] Content is not a string, converting...', typeof content);
      return {
        content: String(content),
        raw: data
      };
    }
    
    console.log('[GPT-5 Chat Completions] Successfully extracted content, length:', content.length);
    
    return {
      content,
      raw: data
    };
  }
}
function buildPrompt(
  fields: string[],
  fieldHints?: Record<string, string[]>,
  payerPlan?: PayerPlan
): string {
  const safeFields = Array.isArray(fields) ? fields : [];
  const fieldList = safeFields.map((f) => `- ${f}`).join("\n");

  let hintsSection = "";
  if (fieldHints && typeof fieldHints === "object" && safeFields.length) {
    hintsSection =
      "\nFIELD SYNONYMS (search only; output keys must match exactly):\n" +
      safeFields
        .map((f) => {
          const hints = fieldHints[f];
          if (!hints || !Array.isArray(hints) || hints.length === 0) return "";
          return `- ${f}: ${hints.join(", ")}`;
        })
        .filter(Boolean)
        .join("\n") +
      "\n";
  }

  // Field-specific extraction instructions
  const fieldSpecificInstructions = {
    'Psychiatric treatment and Psychotherapy': {
      searchTerms: [
        'Psychiatric treatment and Psychotherapy',
        'Psychiatric treatment & Psychotherapy',
        'Psychiatric Treatment',
        'Psychotherapy',
        'Mental Health',
        'Psychiatric care',
        'Psychological treatment'
      ],
      instructions: 'This field is CRITICAL and often missed. Search EVERYWHERE in the document. Look in: 1) Main benefits table, 2) Exclusions/limitations section, 3) Special conditions, 4) Mental health section. Try both "and" and "&" variations. Check for coverage limits, exclusions, or "Not Covered" statements. This field MUST be found - search multiple times if needed.'
    },
    'Al Ahli Hospital': {
      searchTerms: [
        'Al Ahli Hospital',
        'Al-Ahli Hospital',
        'Al Ahli',
        'Provider-specific co-insurance at Al Ahli Hospital',
        'Provider Specific Co-insurance',
        'Additional co-insurance',
        'Additional deductible'
      ],
      instructions: 'This field is CRITICAL and often in a special table. Look for: 1) A table titled "Provider Specific Co-insurance/deductible" or "Additional co-insurance/deductible will apply", 2) Find the row where "Al Ahli Hospital" or "Al-Ahli Hospital" appears, 3) Extract the value in the cell NEXT to "Al Ahli Hospital" (same row, next column), 4) Check for co-insurance percentages or deductible amounts, 5) If not found in special table, check main benefits section. DO NOT confuse with general co-insurance - this must be specifically for Al Ahli Hospital.'
    },
    'Dental Benefit': {
      searchTerms: ['Dental Benefit', 'Dental Coverage', 'Dental Plan', 'Dental', 'Oral Care'],
      instructions: 'Look for a dedicated dental section or benefits table. Check for annual maximums, coverage percentages, or specific procedures covered.'
    },
    'Optical Benefit': {
      searchTerms: ['Optical Benefit', 'Vision Coverage', 'Eye Care', 'Glasses', 'Contact Lenses', 'Vision', 'Eye'],
      instructions: 'Search for vision/optical sections. Look for coverage amounts for frames, lenses, or eye exams. Check for frequency limits (e.g., annual coverage).'
    },
    'Deductible on consultation': {
      searchTerms: ['Deductible on consultations', 'Consultation Deductible', 'OPD Deductible', 'Outpatient Deductible'],
      instructions: 'Check the deductible section, especially for outpatient or consultation services. Look for per-visit or annual deductibles.'
    }
  };

  // Generate field-specific instructions
  const fieldInstructions = Object.entries(fieldSpecificInstructions)
    .filter(([field]) => safeFields.includes(field))
    .map(([field, {searchTerms, instructions}]) => {
      return `\n=== ${field.toUpperCase()} ===\n` +
      `1. Search for these exact terms: ${searchTerms.join(', ')}\n` +
      `2. ${instructions}\n` +
      `3. If not found, check these alternative locations:\n` +
      `   - Benefits Summary section\n` +
      `   - Coverage Details\n` +
      `   - Policy Schedule\n` +
      `4. If still not found, use 'null'`;
    }).join('\n\n');

  // General extraction instructions
  const generalInstructions = "\n=== GENERAL EXTRACTION RULES ===\n" +
  "1. Search for field names THOROUGHLY throughout the ENTIRE document\n" +
  "2. Use CASE-INSENSITIVE matching (e.g., 'Psychiatric' = 'psychiatric')\n" +
  "3. Try MULTIPLE variations of field names (&/and, singular/plural)\n" +
  "4. For tables, look for field names in the left column and values in the right column\n" +
  "5. Check MULTIPLE sections: main benefits, exclusions, limitations, special tables\n" +
  "6. Preserve all original formatting (QAR, %, dates, etc.)\n" +
  "7. If a field is not found after THOROUGH searching, use 'null' (without quotes)\n" +
  "8. For boolean fields, use 'true' or 'false' (without quotes)\n" +
  "9. CRITICAL: Some fields appear in special tables (e.g., 'Provider Specific Co-insurance') - check these too";

  const specificInstructions = generalInstructions;

  return (
    "You are an excellent insurance policy data extraction expert for Al-Ahli hospital with PERFECT ACCURACY. Your sole purpose is to extract data from insurance PDFs with 100% precision. You analyze documents in detail and extract ONLY what is explicitly present. Never infer or hallucinate values that aren't clearly stated. Your output must be clean, consistent, and exactly match the document's content. Return NULL for any field you cannot find with certainty.\n\n" +
    "Extract the following fields from the insurance document with MAXIMUM ACCURACY.\n\n" +
    "=== EXTRACTION RULES ===\n" +
    "1. Search in this order: tables (left column = field, right column = value) ‚Üí text sections\n" +
    "2. Extract COMPLETE values including conditions, percentages, and amounts\n" +
    "3. Preserve original formatting (QAR, %, dates, etc.) exactly as shown\n" +
    "4. If field not found, use 'null' (without quotes)\n\n" +
    "=== OUTPUT FORMAT (MUST FOLLOW EXACTLY) ===\n" +
    "```markdown\n" +
    "| Field Name | Value |\n" +
    "|------------|-------|\n" +
    "| Field 1    |  Value 1 |\n" +
    "| Field 2    | null |\n" +
    "```\n\n" +
    "=== IMPORTANT ===\n" +
    "- Return ONLY the markdown table, no other text\n" +
    "- Use 'null' for missing fields\n" +
    "- Keep all original formatting\n" +
    "- DO NOT include explanations or notes\n\n" +
    specificInstructions +
    "\n\n=== FIELDS TO EXTRACT (exact names) ===\n" +
    fieldList +
    "\n\n Use your best judgement for extracting the right values" +
    "\nReturn ONLY the markdown table with exactly 2 columns, no other text."
  );
}

async function fileToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      if (typeof reader.result === 'string') {
        // Remove the data URL prefix (e.g., "data:application/pdf;base64,")
        const base64 = reader.result.split(',')[1];
        resolve(base64);
      } else {
        reject(new Error('Failed to read file as base64'));
      }
    }; reader.onerror = () => reject(reader.error);
    reader.readAsDataURL(file);
  });
}

/**
 * CLEVER METHOD 1: Extract all tables from markdown into structured format
 * This allows us to search tables systematically without re-parsing
 */
function extractAllTables(markdown: string): Array<{
  title: string;
  headers: string[];
  rows: string[][];
  rawText: string;
  startIndex: number;
}> {
  const tables = [];
  const lines = markdown.split('\n');
  let i = 0;
  
  while (i < lines.length) {
    const line = lines[i];
    
    // Check if this is a table line (starts with |)
    if (line.trim().startsWith('|')) {
      // Look back for table title (usually just before table)
      let title = '';
      if (i > 0 && !lines[i-1].trim().startsWith('|') && lines[i-1].trim().length > 0) {
        title = lines[i-1].trim();
      }
      
      // Extract table
      const tableStart = i;
      const tableLines = [];
      
      while (i < lines.length && lines[i].trim().startsWith('|')) {
        tableLines.push(lines[i]);
        i++;
      }
      
      if (tableLines.length >= 2) {
        // Parse table
        const headers = tableLines[0]
          .split('|')
          .map(h => h.trim())
          .filter(h => h.length > 0 && !h.match(/^-+$/));
        
        // Skip separator line (usually line 1)
        const rows = [];
        for (let j = 1; j < tableLines.length; j++) {
          const cells = tableLines[j]
            .split('|')
            .map(c => c.trim())
            .filter((c, idx) => idx > 0 && idx <= headers.length);
          
          // Skip separator lines
          if (!cells.every(c => c.match(/^-*$/))) {
            rows.push(cells);
          }
        }
        
        tables.push({
          title,
          headers,
          rows,
          rawText: tableLines.join('\n'),
          startIndex: tableStart
        });
        
        console.log(`[Table Extraction] Found table "${title}" with ${rows.length} rows and ${headers.length} columns`);
      }
    }
    
    i++;
  }
  
  console.log(`[Table Extraction] Total tables found: ${tables.length}`);
  return tables;
}

/**
 * CLEVER METHOD 2: Search for field in structured tables
 * Much faster and more accurate than searching raw markdown
 */
function searchFieldInTables(
  fieldName: string,
  fieldVariations: string[],
  tables: Array<{title: string; headers: string[]; rows: string[][]}>
): { value: any; source: string; confidence: number } | null {
  
  const allFieldNames = [fieldName, ...fieldVariations];
  
  // Normalize field names for comparison
  const normalizeField = (f: string) => f.toLowerCase().replace(/[^a-z0-9]/g, '');
  const normalizedTargets = allFieldNames.map(normalizeField);
  
  for (let tableIdx = 0; tableIdx < tables.length; tableIdx++) {
    const table = tables[tableIdx];
    
    // Search in each row
    for (let rowIdx = 0; rowIdx < table.rows.length; rowIdx++) {
      const row = table.rows[rowIdx];
      
      // Typically, field name is in first column, value in second
      if (row.length >= 2) {
        const cellName = row[0];
        const cellValue = row[1];
        const normalizedCellName = normalizeField(cellName);
        
        // Check if this row matches our field
        for (const normalizedTarget of normalizedTargets) {
          if (normalizedCellName === normalizedTarget || 
              normalizedCellName.includes(normalizedTarget) ||
              normalizedTarget.includes(normalizedCellName)) {
            
            console.log(`[Table Search] Found "${fieldName}" in table "${table.title}", row ${rowIdx}: ${cellValue}`);
            
            return {
              value: cellValue,
              source: `Table "${table.title}", row ${rowIdx + 1}`,
              confidence: 0.95  // High confidence for exact table match
            };
          }
        }
      }
      
      // Also check if field name appears in any other column (for multi-column tables)
      for (let colIdx = 0; colIdx < row.length - 1; colIdx++) {
        const cellName = row[colIdx];
        const normalizedCellName = normalizeField(cellName);
        
        for (const normalizedTarget of normalizedTargets) {
          if (normalizedCellName === normalizedTarget) {
            const cellValue = row[colIdx + 1];
            console.log(`[Table Search] Found "${fieldName}" in table "${table.title}", row ${rowIdx}, col ${colIdx}: ${cellValue}`);
            
            return {
              value: cellValue,
              source: `Table "${table.title}", row ${rowIdx + 1}, col ${colIdx + 1}`,
              confidence: 0.90
            };
          }
        }
      }
    }
  }
  
  return null;
}

/**
 * CLEVER METHOD 3: Chunk large documents with overlap
 * Prevents missing fields at chunk boundaries
 */
function chunkMarkdown(markdown: string, chunkSize: number, overlap: number): string[] {
  if (markdown.length <= chunkSize) {
    return [markdown];
  }
  
  const chunks = [];
  let start = 0;
  
  while (start < markdown.length) {
    const end = Math.min(start + chunkSize, markdown.length);
    const chunk = markdown.substring(start, end);
    chunks.push(chunk);
    
    // Move start forward, but with overlap
    start = end - overlap;
    
    // If we're at the end, break
    if (end === markdown.length) break;
  }
  
  console.log(`[Chunking] Split document into ${chunks.length} chunks (size: ${chunkSize}, overlap: ${overlap})`);
  return chunks;
}

/**
 * CLEVER METHOD 4: Regex validation for common field patterns
 */
function validateExtractedValueWithRegex(fieldName: string, value: string): { valid: boolean; suggestion?: string } {
  if (!value || value === 'null') return { valid: true };
  
  const patterns: Record<string, { regex: RegExp; description: string }> = {
    // QAR amounts
    amount: { regex: /QAR\s*[\d,]+(?:\s*(?:per|\/)\s*\w+)?/i, description: 'QAR amount' },
    // Percentages
    percentage: { regex: /\d+\s*%/, description: 'percentage' },
    // Dates
    date: { regex: /\d{1,2}[-\/]\d{1,2}[-\/]\d{2,4}/, description: 'date' },
    // Policy numbers
    policyNumber: { regex: /[A-Z0-9\-]{5,}/, description: 'policy number' },
    // Coverage terms
    coverage: { regex: /(?:covered|not covered|nil|yes|no)/i, description: 'coverage term' }
  };
  
  // Field-specific validation
  const lowerField = fieldName.toLowerCase();
  
  if (lowerField.includes('date')) {
    if (!patterns.date.regex.test(value)) {
      return { valid: false, suggestion: 'Expected date format (DD/MM/YYYY or similar)' };
    }
  }
  
  if (lowerField.includes('policy') && lowerField.includes('number')) {
    if (!patterns.policyNumber.regex.test(value)) {
      return { valid: false, suggestion: 'Expected policy number format' };
    }
  }
  
  if (lowerField.includes('co-insurance') || lowerField.includes('coinsurance')) {
    if (!patterns.percentage.regex.test(value) && !patterns.coverage.regex.test(value)) {
      return { valid: false, suggestion: 'Expected percentage or coverage term' };
    }
  }
  
  // Check if value looks like a valid extraction (not just punctuation or very short)
  if (value.length < 2 && !patterns.percentage.regex.test(value)) {
    return { valid: false, suggestion: 'Value too short' };
  }
  
  return { valid: true };
}

/**
 * CLEVER METHOD 5: Document structure extraction
 * Map the document structure first to understand where fields might be
 */
async function extractDocumentStructure(markdown: string, apiKey: string): Promise<{
  sections: string[];
  tableLocations: string[];
  fieldHints: Record<string, string>;
}> {
  const prompt = `Analyze this insurance policy document and extract its structure.

Return a JSON object with:
{
  "sections": ["section names in order"],
  "tableLocations": ["where tables appear"],
  "fieldHints": {"fieldName": "likely section where it appears"}
}

Document:

${markdown.substring(0, 4000)}... [truncated for structure analysis]

Return ONLY valid JSON.`;

  try {
    const result = await callGPT5Responses({
      apiKey,
      userPrompt: prompt,
      systemPrompt: "You are a document structure analyzer. Return only valid JSON.",
      responseFormat: 'json_object'
    });

    if (result.content) {
      const structure = JSON.parse(result.content);
      console.log('[Document Structure] Extracted:', structure);
      return structure;
    }
  } catch (error) {
    console.warn('[Document Structure] Extraction failed:', error);
  }
  
  return { sections: [], tableLocations: [], fieldHints: {} };
}

/**
 * Extracts a single field with high precision (data science approach)
 */
async function extractSingleField(
  markdown: string,
  fieldName: string,
  fieldHints: string[],
  apiKey: string
): Promise<{ value: any; confidence: number }> {
  const hintsText = fieldHints.length > 0 
    ? `\nAlternative names to search for: ${fieldHints.join(", ")}`
    : "";
  
  const prompt = `You are an expert at extracting a SINGLE field from insurance documents.

TARGET FIELD: "${fieldName}"
${hintsText}

TASK: Find the value for "${fieldName}" in the markdown document below.

SEARCH STRATEGY:
1. Check ALL tables in the document
2. Try exact match and case-insensitive match
3. Try alternative names: & vs and, plural vs singular
4. Check special tables (e.g., Provider Specific Co-insurance for Al Ahli Hospital)

OUTPUT FORMAT - Return a JSON object:
{
  "field": "${fieldName}",
  "value": "extracted value or null if not found",
  "confidence": 0.95,
  "source": "description of where found (e.g., 'Main benefits table, row 5')"
}

MARKDOWN DOCUMENT:

${markdown}

Return ONLY the JSON object.`;

  try {
    const result = await callGPT5Responses({
      apiKey,
      userPrompt: prompt,
      systemPrompt: "You are a precision field extractor. Return valid JSON only.",
      responseFormat: 'json_object'
    });

    if (result.content) {
      const parsed = JSON.parse(result.content);
      console.log(`[Single Field] ${fieldName}: ${parsed.value} (confidence: ${parsed.confidence}, source: ${parsed.source})`);
      return {
        value: parsed.value === "null" ? null : parsed.value,
        confidence: parsed.confidence || 0.5
      };
    }
  } catch (error) {
    console.warn(`Single field extraction failed for ${fieldName}:`, error);
  }
  
  return { value: null, confidence: 0 };
}

/**
 * Extracts specific fields from markdown text
 */
async function extractFieldsFromMarkdown(
  markdown: string,
  fields: string[],
  apiKey: string,
  payerPlan?: PayerPlan
): Promise<Record<string, any>> {
  const fieldList = fields.map((f) => `- ${f}`).join("\n");
  
  // Build field hints if available, including automatic & <-> and variations
  let hintsSection = "";
  if (payerPlan && FIELD_SUGGESTIONS[payerPlan]) {
    const fieldHints = FIELD_SUGGESTIONS[payerPlan];
    hintsSection =
      "\n\nFIELD SYNONYMS (search for these alternative names):\n" +
      fields
        .map((f) => {
          const hints = fieldHints[f];
          const hintsList = hints && Array.isArray(hints) ? [...hints] : [];
          
          // Automatically add & <-> and variations
          if (f.includes('&')) {
            hintsList.push(f.replace(/\s*&\s*/g, ' and '));
          } else if (f.includes(' and ')) {
            hintsList.push(f.replace(/\s+and\s+/g, ' & '));
          }
          
          if (hintsList.length === 0) {
            // If no hints but field has & or and, still add variations
            if (f.includes('&')) {
              return `- ${f}: also look for: ${f.replace(/\s*&\s*/g, ' and ')}`;
            } else if (f.includes(' and ')) {
              return `- ${f}: also look for: ${f.replace(/\s+and\s+/g, ' & ')}`;
            }
            return "";
          }
          
          return `- ${f}: also look for: ${hintsList.join(", ")}`;
        })
        .filter(Boolean)
        .join("\n");
  } else {
    // Even without payer-specific hints, add & <-> and variations
    const fieldVariations = fields
      .map((f) => {
        const variations: string[] = [];
        if (f.includes('&')) {
          variations.push(f.replace(/\s*&\s*/g, ' and '));
        } else if (f.includes(' and ')) {
          variations.push(f.replace(/\s+and\s+/g, ' & '));
        }
        
        if (variations.length > 0) {
          return `- ${f}: also look for: ${variations.join(", ")}`;
        }
        return "";
      })
      .filter(Boolean);
    
    if (fieldVariations.length > 0) {
      hintsSection = "\n\nFIELD SYNONYMS (search for these alternative names):\n" + 
                     fieldVariations.join("\n");
    }
  }

  // Few-shot examples to guide the model (data science approach)
  const fewShotExamples = `
EXAMPLE 1 - Table Extraction:
If markdown contains:
| Benefit | Coverage |
|---------|----------|
| Dental Benefit | QAR 500 per year |
| Optical Benefit | Not covered |

Then extract:
| Field Name | Value |
|------------|-------|
| Dental Benefit | QAR 500 per year |
| Optical Benefit | Not covered |

EXAMPLE 2 - Provider-Specific Table:
If markdown contains a table titled "Provider Specific Co-insurance":
| Provider | Co-insurance |
|----------|--------------|
| Al Ahli Hospital | 10% |
| Other providers | 20% |

Then for "Al Ahli Hospital" field, extract: 10%

EXAMPLE 3 - Field Name Variations:
If searching for "Psychiatric treatment and Psychotherapy" and document has:
| Benefit | Coverage |
|---------|----------|
| Psychiatric treatment & Psychotherapy | QAR 1000 |

Then extract: QAR 1000 (even though "&" vs "and" differs)

EXAMPLE 4 - Missing Field:
If searching for "Dental Coverage" and it's truly not in any table or text:
| Field Name | Value |
|------------|-------|
| Dental Coverage | null |
`;

  const prompt = `You are an expert insurance policy data extraction assistant with PERFECT ACCURACY.

You will be given a MARKDOWN document (converted from a PDF insurance policy). Your task is to extract specific fields from this markdown with 100% precision.

${fewShotExamples}

CRITICAL EXTRACTION RULES:

1. **Search Strategy - CHECK ALL TABLES FIRST**:
   - STEP 1: Count how many tables exist in the markdown document
   - STEP 2: Search EACH table systematically for the field:
     * Main benefits table (usually the first/largest table)
     * Provider-specific tables (e.g., "Provider Specific Co-insurance/deductible")
     * Exclusions or limitations tables
     * Any other tables in the document
   - STEP 3: For each table, scan EVERY row looking for the field name
   - STEP 4: Check synonyms and alternative field names (see field synonyms below)
   - STEP 5: Look in text sections if not found in any table
   - IMPORTANT: When searching for field names, also check for "&" vs "and" variations
     Example: "Vaccination & Immunization" might appear as "Vaccination and Immunization"
   - Be case-insensitive: "Psychiatric" = "psychiatric", "Childbirth" = "childbirth"

2. **Accuracy Requirements**:
   - Extract ONLY what is explicitly present in the document
   - NEVER infer or hallucinate values
   - If a field is not found with certainty, use 'null'
   - Preserve exact formatting (QAR, %, dates, etc.)

3. **Table Parsing (CRITICAL - Most Data is in Tables)**:
   - VERIFY: Count how many tables exist in the markdown - check ALL of them
   - Tables use | separators in markdown
   - Field names are typically in the left column (first column)
   - Values are in the right column (second column or adjacent column)
   - Multi-column tables: scan all columns to find field names
   - Check EVERY row in EVERY table - don't skip any rows
   - Extract complete values including conditions, percentages, amounts
   - Special tables (e.g., "Provider Specific Co-insurance") contain critical fields
   - If you don't find a field in the main table, check OTHER tables

4. **Value Extraction**:
   - Include all details (amounts, percentages, conditions)
   - Keep original formatting exactly as shown
   - For multi-part values, include the complete text

5. **Field Name Matching**:
   - Be flexible with "&" and "and" - treat them as equivalent
   - Be flexible with capitalization (e.g., "Childbirth" vs "childbirth")
   - Example matches:
     ‚Ä¢ "Vaccinations & Immunizations" = "Vaccinations and Immunizations"
     ‚Ä¢ "Pregnancy & Childbirth" = "Pregnancy and childbirth"
     ‚Ä¢ "Psychiatric treatment and Psychotherapy" = "Psychiatric treatment and Psychotherapy"
   - Always return the EXACT field name as requested (with exact capitalization and & if specified)

6. **CRITICAL FIELDS - FREQUENTLY MISSED**:
   
   A. **Al Ahli Hospital** (if requested):
      - This field is FREQUENTLY MISSED - pay extra attention
      - Look for a table titled "Provider Specific Co-insurance/deductible" or similar
      - Table may say: "Additional co-insurance/deductible will apply on all services in below mentioned providers"
      - Find the row where "Al Ahli Hospital" or "Al-Ahli Hospital" is mentioned
      - Extract the value in the cell BESIDE/NEXT TO "Al Ahli Hospital" (same row, next column)
      - The value might be: a percentage (e.g., "10%"), an amount (e.g., "QAR 100"), or "Not applicable"
      - DO NOT confuse with general co-insurance - this must be SPECIFIC to Al Ahli Hospital
      - If the special table doesn't exist, return 'Not applicable'
   
   B. **Psychiatric treatment and Psychotherapy** (if requested):
      - This field is FREQUENTLY MISSED - search thoroughly
      - Try BOTH variations: "Psychiatric treatment and Psychotherapy" AND "Psychiatric treatment & Psychotherapy"
      - Search in multiple sections: main benefits table, exclusions, limitations, mental health
      - May appear as: "Psychiatric Treatment", "Psychotherapy", "Mental Health Coverage"
      - Look for: coverage amounts, limits, exclusions, or "Not Covered" statements
      - Be case-insensitive when searching (e.g., "childbirth" vs "Childbirth")
      - Search the ENTIRE document - check every table and text section

OUTPUT FORMAT (MUST FOLLOW EXACTLY):
\`\`\`markdown
| Field Name | Value |
|------------|-------|
| Field 1    | Value 1 |
| Field 2    | null |
\`\`\`

IMPORTANT:
- Return ONLY the markdown table, no other text or explanations
- Use 'null' for missing fields (without quotes)
- Keep all original formatting from the document
- Match field names EXACTLY as provided below

${hintsSection}

FIELDS TO EXTRACT (exact names):
${fieldList}

MARKDOWN DOCUMENT TO ANALYZE:

${markdown}

Return ONLY the markdown table with exactly 2 columns: Field Name and Value.`;

  // Data science approach: Use gpt-5 Responses API for better reasoning
  let content;
  let modelUsed = EXTRACTION_CONFIG.PRIMARY_MODEL;
  
  try {
    // Try gpt-5 first using Responses API
    const result = await callGPT5Responses({
      apiKey,
      userPrompt: prompt,
      responseFormat: 'text'
    });
    
    content = result.content;
    
    if (!content) {
      throw new Error('No content returned from GPT-5 Responses API');
    }
  } catch (error) {
    // Fallback to secondary gpt-5 call if primary fails
    console.warn('Primary gpt-5 call failed, retrying:', error);
    modelUsed = EXTRACTION_CONFIG.FALLBACK_MODEL;
    
    const result = await callGPT5Responses({
      apiKey,
      userPrompt: prompt,
      systemPrompt: "You are a medical insurance policy data extraction expert with PERFECT ACCURACY. Extract data from markdown documents with 100% precision.",
      responseFormat: 'text'
    });
    
    content = result.content;
    
    if (!content) {
      throw new Error('Field extraction failed: No content returned from fallback');
    }
  }
  
  console.log(`Extraction using model: ${modelUsed}`);
  console.log('Field extraction response:', content);
  console.log('Field extraction response type:', typeof content);

  // Ensure content is a string
  if (typeof content !== 'string') {
    console.error('Content is not a string, received:', content);
    throw new Error(`Expected string content but received ${typeof content}`);
  }

  // Parse the markdown table response
  const extractedData = parseMarkdownTable(content);
  return extractedData;
}

/**
 * Revalidates and improves extracted field values with a second LLM pass
 */
async function revalidateExtractedFields(
  markdown: string,
  initialExtraction: Record<string, any>,
  fields: string[],
  apiKey: string,
  passNumber: number = 1
): Promise<Record<string, any>> {
  console.log(`Starting field revalidation (Pass ${passNumber})...`);
  
  // Format the initial extraction for context
  const initialResults = Object.entries(initialExtraction)
    .map(([field, value]) => `  ‚Ä¢ ${field}: ${value === null ? 'NOT FOUND' : value}`)
    .join('\n');
  
  const fieldList = fields.map((f) => `- ${f}`).join("\n");
  
  const passDescription = passNumber === 1 
    ? "SECOND PASS VALIDATION" 
    : "THIRD PASS - FINAL CROSS-CHECK";
  
  const passInstructions = passNumber === 1
    ? "Your task: REVALIDATE and IMPROVE the extraction with 100% accuracy."
    : "Your task: FINAL CROSS-CHECK - verify EVERY field one more time with MAXIMUM scrutiny. This is the last chance to catch any errors or missing values.";
  
  const prompt = `You are an expert insurance policy data validator with PERFECT ACCURACY.

${passDescription}

You will receive:
1. A MARKDOWN document (insurance policy)
2. Previous extraction results
3. A list of fields that need revalidation

${passInstructions}

PREVIOUS EXTRACTION (may have errors or missing values):
${initialResults}

REVALIDATION RULES:

1. **Verify EVERY Field Systematically**:
   - Re-search the ENTIRE markdown for EACH field individually
   - For each field, check ALL tables in the document - don't skip any
   - Verify the current value is correct by finding it again in the source
   - If value is missing (NOT FOUND), do an exhaustive search:
     * Check every table (count them - did you check them all?)
     * Check every text section
     * Try all possible name variations
   - If value seems wrong or generic, find the correct specific value

2. **Comprehensive Table Search Strategy**:
   - CRITICAL: Tables contain most field values - check them thoroughly
   - Count how many tables are in the markdown document
   - Check EACH table systematically:
     * Main benefits table (usually the largest)
     * Provider-specific tables (e.g., "Provider Specific Co-insurance/deductible")
     * Exclusions/limitations tables
     * Additional benefits tables
     * Special conditions tables
   - For each table, scan EVERY row for the field name
   - Look for field names with variations (&/and, singular/plural, case differences)
   - Check both left column (field names) and headers (for multi-column tables)
   
   **CRITICAL FIELDS (frequently missed - double check these):**
   - "Al Ahli Hospital": This is often in a SEPARATE table titled "Provider Specific Co-insurance/deductible". Find the row with "Al Ahli Hospital" and extract value from NEXT column. If no special table exists, return 'Not applicable'.
   - "Psychiatric treatment and Psychotherapy": Try both "and" and "&". Search ALL tables. Check: benefits table, exclusions table, mental health sections. Look for variations: "Psychiatric Treatment", "Psychotherapy", "Mental Health".

3. **Quality Checks for Each Value**:
   - Does the value make sense for this field type?
   - Is the formatting correct (QAR, %, dates, amounts)?
   - Is it complete with all conditions/details?
   - Does it look like a complete answer or truncated?
   - Are there any obvious errors or placeholders?
   - Did you extract from the correct table row/column?

4. **Improvement Focus**:
   - Fields marked as "NOT FOUND" - search HARDER, check EVERY table again
   - Values that seem generic or vague - find specific details
   - Missing conditions or percentages - include them fully
   - Incomplete information - extract the complete value
   - Suspicious values - verify against source table

5. **Output Requirements**:
   - Return ALL fields (even if value doesn't change from previous pass)
   - Use 'null' ONLY if truly not found after checking EVERY table
   - Preserve exact formatting from document (QAR, %, etc.)
   - Return EXACT field names as requested (match case and punctuation)

FIELDS TO REVALIDATE:
${fieldList}

MARKDOWN DOCUMENT:

${markdown}

Return ONLY a markdown table with exactly 2 columns: Field Name and Value.

OUTPUT FORMAT:
\`\`\`markdown
| Field Name | Value |
|------------|-------|
| Field 1    | Value 1 |
| Field 2    | null |
\`\`\``;

  let content;
  
  try {
    const result = await callGPT5Responses({
      apiKey,
      userPrompt: prompt,
      systemPrompt: "You are an expert insurance policy data validator. Your job is to revalidate and improve field extractions with 100% accuracy.",
      responseFormat: 'text'
    });
    
    content = result.content;
    
    if (!content) {
      console.warn('No content returned from revalidation');
      return initialExtraction;
    }
  } catch (error) {
    console.warn(`Revalidation failed:`, error);
    // Return original extraction if revalidation fails
    return initialExtraction;
  }

  console.log('Revalidation response received');

  // Parse the revalidated data
  const revalidatedData = parseMarkdownTable(content);
  
  // Log changes
  console.log(`\n=== REVALIDATION RESULTS (Pass ${passNumber}) ===`);
  let changesCount = 0;
  for (const field of fields) {
    const oldValue = initialExtraction[field];
    const newValue = revalidatedData[field];
    if (oldValue !== newValue) {
      changesCount++;
      console.log(`üìù ${field}:`);
      console.log(`   Before: ${oldValue === null ? 'null' : oldValue}`);
      console.log(`   After:  ${newValue === null ? 'null' : newValue}`);
    }
  }
  
  if (changesCount === 0) {
    console.log('‚úì No changes - all values verified as correct');
  } else {
    console.log(`\nTotal changes in Pass ${passNumber}: ${changesCount} field(s) improved`);
  }
  
  return revalidatedData;
}

/**
 * Extract text from PDF using pdfjs-dist (browser-compatible)
 */
async function extractTextFromPDF(file: File): Promise<string> {
  console.log('[PDF Parser] Starting text extraction...');
  
  const arrayBuffer = await file.arrayBuffer();
  const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
  
  console.log(`[PDF Parser] Total pages: ${pdf.numPages}`);
  
  let fullText = '';
  
  // Extract text from each page
  for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
    const page = await pdf.getPage(pageNum);
    const textContent = await page.getTextContent();
    
    // Combine all text items
    const pageText = textContent.items
      .map((item: any) => item.str)
      .join(' ');
    
    fullText += `\n\n=== PAGE ${pageNum} ===\n\n${pageText}`;
  }
  
  console.log(`[PDF Parser] Extracted ${fullText.length} characters`);
  return fullText;
}

/**
 * Extract fields directly from PDF text using OpenAI (SIMPLIFIED APPROACH)
 */
async function extractFieldsDirectly(
  pdfText: string,
  fieldsToExtract: string[],
  apiKey: string,
  payerPlan?: PayerPlan,
  payerPlanName?: string
): Promise<Record<string, any>> {
  console.log('[OpenAI] Extracting fields directly from PDF text...');
  
  const prompt = `You are an expert at extracting data from insurance policy documents.

DOCUMENT CONTEXT:
- Payer Plan: ${payerPlanName || payerPlan || 'Insurance Policy'}
- This is an insurance benefits document that contains policy details and coverage information.

FIELDS TO EXTRACT:
${fieldsToExtract.map((field, idx) => `${idx + 1}. ${field}`).join('\n')}

EXTRACTION RULES:
1. Extract ONLY the actual values, NOT descriptions or explanations
2. For percentages, return just the number with % (e.g., "20%")
3. For currency amounts, include currency and amount (e.g., "QAR 7,500", "QAR 100")
4. For coverage limits, use exact wording (e.g., "Unlimited", "Not covered", "QAR 50,000")
5. For multiple values (like co-insurance per hospital), list them clearly separated by commas
6. For dates, use format: DD/MM/YYYY
7. For "Not Found" or missing fields, return null
8. Be precise - extract exactly what's in the document, no interpretation

IMPORTANT:
- Look for values in tables, headers, and body text
- Check both page 1 (header/policy info) and subsequent pages (benefits tables)
- For fields like Policy Number, Category, Effective Date - check the header section
- For benefits like co-insurance, deductibles, coverage - check benefits tables

if any field is null or not found, then send it as "Nil" in the output.
  
DOCUMENT TEXT:
${pdfText}

OUTPUT:
Return a JSON object where each key is a field name and the value is the extracted data (or null if not found).
Example:
{
  "Policy Number": "123456",
  "Category": "Premium",
  "Co-insurance": "20%",
  "Dental Benefit": "QAR 7,500, 20% co-insurance"
}

Extract the fields now:`;
console.log('prompt', prompt)
console.log('EXTRACTION_CONFIG.PRIMARY_MODEL', EXTRACTION_CONFIG.PRIMARY_MODEL)
  const response = await fetch(OPENAI_CHAT_ENDPOINT, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: EXTRACTION_CONFIG.PRIMARY_MODEL,
      messages: [
        {
          role: 'user',
          content: prompt
        }
      ],
      response_format: { type: "json_object" }
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
  }

  const data = await response.json();
  const content = data.choices[0].message.content;
  
  console.log('[OpenAI] Extraction response received');
  console.log('[OpenAI] Raw response:', content);
  
  return JSON.parse(content);
}

/**
 * Converts a PDF to Markdown format with specific rules (DEPRECATED)
 * Now using extractTextFromPDF instead for simplicity
 */
async function convertPDFToMarkdown(file: File, apiKey: string): Promise<string> {
  console.log('Converting PDF to Markdown...');
  
  // Upload the PDF file to OpenAI
  const fileId = await uploadFileToOpenAI(file, apiKey);
  
  const prompt = `You are an expert PDF to Markdown converter. Your task is to convert this PDF document to clean, well-formatted Markdown.

CRITICAL RULES YOU MUST FOLLOW:

1. **COMPLETE CONTENT EXTRACTION (HIGHEST PRIORITY)**:
   - Extract EVERY SINGLE CHARACTER from the document
   - DO NOT skip, miss, or omit ANY content whatsoever
   - Extract ALL text from EVERY page - nothing should be left behind
   - Include ALL data from tables, paragraphs, sections, and subsections
   - If you see text in the PDF, it MUST appear in the markdown output
   - Missing even a single field or value is UNACCEPTABLE
   - Extract 100% of the document content with ZERO exceptions

2. **TABLE PRESERVATION (CRITICAL - TABLES CONTAIN MOST IMPORTANT DATA)**: 
   - Tables are the PRIMARY source of field values - extract them with 100% accuracy
   - Preserve ALL tables EXACTLY as they appear in the PDF
   - Extract EVERY SINGLE ROW - do not skip any rows
   - Extract EVERY SINGLE COLUMN - do not skip any columns
   - Extract EVERY CELL VALUE completely - including all text, numbers, percentages, amounts
   - Use proper Markdown table syntax with | separators
   - Maintain exact row and column structure
   - Keep all table headers, labels, and values intact
   - If a table has 50 rows, the markdown must have 50 rows
   - Special tables (e.g., "Provider Specific Co-insurance") are CRITICAL - extract completely
   - Multi-column tables: preserve all columns with proper alignment
   - Merged cells: extract the content and indicate the span
   - Tables within sections: extract ALL of them, not just the main table
   - VERIFY: After extracting a table, count the rows - did you extract them all?

3. **Header Handling**:
   - Keep the header ONLY from the FIRST page
   - REMOVE headers from ALL subsequent pages
   - Headers typically include company logos, document titles at the top

4. **Footer Handling**:
   - REMOVE ALL footers from EVERY page
   - Footers typically include page numbers, company info, disclaimers at the bottom

5. **Content Preservation**:
   - Preserve ALL body content from EVERY page
   - Extract ALL paragraphs, sections, and subsections completely
   - Maintain paragraph structure
   - Keep bullet points and numbered lists - extract ALL items
   - Preserve bold and italic formatting where visible
   - Include all field names, values, labels, and descriptions
   - Extract all benefit details, coverage amounts, percentages, and conditions

6. **Output Format**:
   - Return ONLY the Markdown content
   - No explanations or comments
   - Clean, readable Markdown format

REMEMBER: Your #1 priority is COMPLETENESS. Every character in the PDF must be in the markdown output. Missing content will cause critical data extraction failures. Extract EVERYTHING.

Analyze the document carefully and convert it to Markdown following these rules exactly.`;

  // Use Assistants API with file_search to process the PDF
  const response = await createAssistantAndRun({ 
    apiKey, 
    fileId, 
    prompt,
    model: "gpt-4o"
  });

  // Extract markdown content from response
  let markdown = '';
  if (response.data?.[0]?.content?.[0]?.text?.value) {
    markdown = response.data[0].content[0].text.value;
  } else {
    throw new Error('No markdown content returned from PDF conversion');
  }

  console.log('PDF to Markdown conversion completed');
  console.log('Markdown length:', markdown.length);
  
  return markdown;
}

async function uploadFileToOpenAI(file: File, apiKey: string): Promise<string> {
  const form = new FormData();
  form.append("purpose", "assistants");
  form.append("file", file, file.name);

  const res = await fetch(`${OPENAI_BASE}/files`, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
    },
    body: form,
  });

  if (!res.ok) {
    const text = await res.text();
    throw new Error(`OpenAI file upload failed: ${res.status} ${text}`);
  }

  const data = await res.json();
  return data.id as string;
}

async function callChatCompletion(params: {
  apiKey: string;
  prompt: string;
  model?: string;
}): Promise<any> {
  const { apiKey, prompt, model = "gpt-5" } = params;

  // Use GPT-5 Responses API
  const result = await callGPT5Responses({
    apiKey,
    userPrompt: prompt,
    systemPrompt: "You are a medical insurance policy data extraction expert with PERFECT ACCURACY. Your sole purpose is to extract data from insurance PDFs with 100% precision. You analyze documents in detail and extract ONLY what is explicitly present. Never infer or hallucinate values that aren't clearly stated. Your output must be clean, consistent, and exactly match the document's content. Return NULL for any field you cannot find with certainty.",
    responseFormat: 'text'
  });

  console.log('GPT-5 Responses API response:', result.content);
  return result.content;
}

async function createAssistantAndRun(params: {
  apiKey: string;
  fileId: string;
  prompt: string;
  model?: string;
}): Promise<any> {
  const { apiKey, fileId, prompt, model = "gpt-5" } = params;

  // Create assistant with file search capability and enhanced instructions
  const assistantRes = await fetch(`${OPENAI_BASE}/assistants`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
    body: JSON.stringify({
      model,
      name: "Medical Insurance Extractor",
      description: "Specialized assistant for extracting medical insurance policy data with high precision",
      instructions: "You are a medical insurance policy data extraction expert with PERFECT ACCURACY. Your PRIMARY GOAL is to extract EVERY SINGLE CHARACTER from the PDF document - DO NOT miss any content. Extract 100% of all text, tables, fields, and values from the document. Missing content is UNACCEPTABLE. After complete extraction, your secondary goal is precision - extract ONLY what is explicitly present, never infer or hallucinate values. Your output must be clean, consistent, and exactly match the document's content. Extract ALL tables completely with every row and column. Return NULL only for fields that truly don't exist after extracting all content.",
      tools: [{ type: "file_search" }],
      tool_resources: {
        file_search: {
          vector_store_ids: []
        }
      },
    }),
  });

  if (!assistantRes.ok) {
    const errTxt = await assistantRes.text();
    throw new Error(`Assistant creation error: ${assistantRes.status} ${errTxt}`);
  }

  const assistant = await assistantRes.json();

  // Create thread
  const threadRes = await fetch(`${OPENAI_BASE}/threads`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
    body: JSON.stringify({}),
  });

  if (!threadRes.ok) {
    const errTxt = await threadRes.text();
    throw new Error(`Thread creation error: ${threadRes.status} ${errTxt}`);
  }

  const thread = await threadRes.json();

  // Add message with file attachment
  const messageRes = await fetch(`${OPENAI_BASE}/threads/${thread.id}/messages`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
    body: JSON.stringify({
      role: "user",
      content: prompt,
      attachments: [
        {
          file_id: fileId,
          tools: [{ type: "file_search" }]
        }
      ]
    }),
  });

  if (!messageRes.ok) {
    const errTxt = await messageRes.text();
    throw new Error(`Message creation error: ${messageRes.status} ${errTxt}`);
  }

  // Create and poll run
  const runRes = await fetch(`${OPENAI_BASE}/threads/${thread.id}/runs`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
    body: JSON.stringify({
      assistant_id: assistant.id,
    }),
  });

  if (!runRes.ok) {
    const errTxt = await runRes.text();
    throw new Error(`Run creation error: ${runRes.status} ${errTxt}`);
  }

  const run = await runRes.json();

  // Poll for completion
  let runStatus = run;
  while (runStatus.status === "queued" || runStatus.status === "in_progress") {
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const statusRes = await fetch(`${OPENAI_BASE}/threads/${thread.id}/runs/${run.id}`, {
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "OpenAI-Beta": "assistants=v2",
      },
    });

    if (!statusRes.ok) {
      const errTxt = await statusRes.text();
      throw new Error(`Run status check error: ${statusRes.status} ${errTxt}`);
    }

    runStatus = await statusRes.json();
  }

  if (runStatus.status !== "completed") {
    throw new Error(`Run failed with status: ${runStatus.status}`);
  }

  // Get messages
  const messagesRes = await fetch(`${OPENAI_BASE}/threads/${thread.id}/messages`, {
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
  });

  if (!messagesRes.ok) {
    const errTxt = await messagesRes.text();
    throw new Error(`Messages retrieval error: ${messagesRes.status} ${errTxt}`);
  }

  const messages = await messagesRes.json();
  
  // Clean up
  await fetch(`${OPENAI_BASE}/assistants/${assistant.id}`, {
    method: "DELETE",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "OpenAI-Beta": "assistants=v2",
    },
  });

  return messages;
}

function parseMarkdownOutput(resp: any): Record<string, any> {
  // Handle different response formats
  let content = "";
  
  if (resp.choices?.[0]?.message?.content) {
    // Chat completion format
    content = resp.choices[0].message.content;
  } else if (resp.data?.[0]?.content?.[0]?.text?.value) {
    // Assistants API format
    content = resp.data[0].content[0].text.value;
  } else {
    throw new Error("Empty response from OpenAI.");
  }

  if (!content) throw new Error("Empty response from OpenAI.");

  // Parse markdown table format
  const markdownData = parseMarkdownTable(content);
  return postProcessData(markdownData);
}

/**
 * Post-process the extracted data to fix common issues
 */
function postProcessData(data: Record<string, any>): Record<string, any> {
  const result = { ...data };
  
  // Post-process special fields to detect and fix common errors
  const ahliField = 'Provider-specific co-insurance at Al Ahli Hospital';
  const generalCoInsurance = 'Co-insurance';
  const inpatientCoInsurance = 'Co-insurance on all inpatient treatment';
  
  // Check if Al Ahli specific field has a value that doesn't explicitly mention Al Ahli
  if (result[ahliField]) {
    const value = result[ahliField];
    if (typeof value === 'string') {
      const lowerValue = value.toLowerCase();
      const mentionsAlAhli = lowerValue.includes('al ahli') || lowerValue.includes('ahli hospital');
      
      // Any percentage value that doesn't explicitly mention Al Ahli Hospital is considered invalid
      if (/\d+%/.test(value) && !mentionsAlAhli) {
        const oldValue = value;
        result[ahliField] = 'Not applicable';
        console.warn(`[VALIDATION] Forced correction for ${ahliField}: was '${oldValue}', set to 'Not applicable' because it doesn't mention Al Ahli explicitly`);
      }
    }
  }
  
  // Extra validation for duplicate values
  if (result[ahliField] && (result[ahliField] === result[generalCoInsurance] || 
      result[ahliField] === result[inpatientCoInsurance])) {
    const oldValue = result[ahliField];
    result[ahliField] = 'Not applicable';
    console.warn(`[VALIDATION] Corrected identical value for ${ahliField}: was '${oldValue}', set to 'Not applicable' due to duplicate values`);
  }
  
  return result;
}

/**
 * Parses a markdown table into a JSON object
 * Expects format:
 * | Field Name | Value |
 * |------------|-------|
 * | Field 1    | Value 1 |
 * | Field 2    | Value 2 |
 */
function parseMarkdownTable(markdown: string): Record<string, any> {
  const result: Record<string, any> = {};
  
  // Validate input
  if (!markdown || typeof markdown !== 'string') {
    console.error('[parseMarkdownTable] Invalid input:', markdown);
    throw new Error(`Invalid markdown input: expected string, received ${typeof markdown}`);
  }
  
  // Split into lines and remove header and separator rows
  const lines = markdown
    .split('\n')
    .filter(line => line.trim().startsWith('|') && !line.includes('---'));

  // Process each line
  for (const line of lines) {
    // Remove leading/trailing | and split by |
    const cells = line
      .trim()
      .slice(1, -1) // Remove leading and trailing |
      .split('|')
      .map(cell => cell.trim());

    if (cells.length >= 2) {
      const field = cells[0];
      const value = cells[1];
      
      // Only add if we have both field and value
      if (field && value) {
        // Convert 'null' or empty values to null
        result[field] = value.toLowerCase() === 'null' || value === '' ? null : value;
      }
    }
  }

  return result;
}

function validateExtractedValue(value: string | null, fieldName: string): string | null {
  if (value === null) return null;
  
  // Trim the value before processing
  const trimmedValue = value.trim();
  if (!trimmedValue) return null;
  
  // Standard responses that should always pass validation
  const standardResponses = ['covered', 'not covered', 'nil', 'yes', 'no'];
  const lowerValue = trimmedValue.toLowerCase();
  
  // If it's a standard response, return it immediately
  if (standardResponses.includes(lowerValue)) {
    return trimmedValue;
  }
  
  // Check if the value contains QAR or percentage - likely valid
  if (trimmedValue.includes('QAR') || trimmedValue.includes('%') || /\d+/.test(trimmedValue)) {
    // Return values containing important numeric/financial data
    return trimmedValue;
  }
  
  // Reject values that are just punctuation
  if (!/[a-zA-Z0-9]/.test(trimmedValue)) {
    console.warn(`[VALIDATION] Field "${fieldName}" rejected - no alphanumeric content: "${value}"`);
    return null;
  }
  
  // Reject values that are suspiciously short without being standard responses
  if (trimmedValue.length < 2) {
    console.warn(`[VALIDATION] Field "${fieldName}" rejected - suspiciously short value: "${value}"`);
    return null;
  }
  
  // Clean up citation markers if they're still present
  const cleanedValue = trimmedValue.replace(/\[\d+(?::\d+)?(?:‚Ä†[a-z]+)?\]|„Äê\d+(?::\d+)?(?:‚Ä†[a-z]+)?„Äë|\{\d+(?::\d+)?(?:‚Ä†[a-z]+)?\}/g, '').trim();
  
  return cleanedValue || trimmedValue; // Return cleaned value, or original if cleaning made it empty
}

function validateAllExtractedData(data: ExtractedData, fieldNames: string[]): ExtractedData {
  const validated: ExtractedData = {};
  for (const key of fieldNames) {
    const value = data[key] || null;
    validated[key] = validateExtractedValue(value, key);
  }
  return validated;
}


function normalizeLabel(label: string): string {
  return label.toLowerCase().replace(/[^a-z0-9]+/g, " ").trim();
}

// Format QLM specific fields
// Format QLM specific fields -- PATCHED VERSION
function formatQLMFields(normalized: ExtractedData): ExtractedData {
  const result = { ...normalized };
  
  // Preserve exact value for Vaccination field
  const vaccinationField = "Vaccination of children";
  if (result[vaccinationField]) {
    let value = result[vaccinationField] as string;

    // Only format if "QAR" is actually found in the extracted value
    if (typeof value === 'string') {
      const trimmed = value.trim();
      const lowerValue = trimmed.toLowerCase();
      if (
        lowerValue === 'covered' ||
        lowerValue === 'not covered' ||
        lowerValue === 'nil' ||
        lowerValue === 'null'
      ) {
        result[vaccinationField] = trimmed.charAt(0).toUpperCase() + trimmed.slice(1);
      } else if (/qar.*\d/.test(lowerValue)) {
        // Keep QAR value as in extraction result
        result[vaccinationField] = trimmed;
      } else {
        // If the extracted text does NOT include QAR, a currency, OR a number,
        // we should not manufacture a value. Leave as is (or null, if blank).
        result[vaccinationField] = trimmed; // or set to null if you want stricter
      }
    }
  }

}
  

  // Standardize "For Eligible Medical Expenses at Al Ahli Hospital" to percentage format
  const ahliField = "For Eligible Medical Expenses at Al Ahli Hospital";
  if (result[ahliField]) {
    const value = result[ahliField] as string;
    const lowerValue = value.toLowerCase().trim();
    
    // Look for percentage patterns
    const percentMatch = value.match(/(\d{1,3})\s*%/);
    if (percentMatch) {
      // Format as percentage with coverage
      result[ahliField] = `${percentMatch[1]}% covered`;
    } else if (lowerValue === 'covered' || 
               lowerValue.includes('100') || 
               lowerValue.includes('full') || 
               lowerValue.includes('fully') || 
               lowerValue.includes('all')) {
      // Full coverage indicators
      result[ahliField] = "100% covered";
    } else if (lowerValue === 'not covered') {
      result[ahliField] = "Not covered";
    } else if (lowerValue.includes('co-insurance') || lowerValue.includes('coinsurance')) {
      // Try to extract coinsurance percentage
      const coinsuranceMatch = value.match(/(\d{1,2})\s*%\s*(?:co-?insurance|co-?pay)/i);
      if (coinsuranceMatch) {
        const percentage = 100 - parseInt(coinsuranceMatch[1], 10);
        result[ahliField] = `${percentage}% covered`;
      }
    }
  }
  
  // Add handling for deductibles and copayments
  const copaymentFields = ["Dental Copayment", "Maternity Copayment", "Optical Copayment"];
  copaymentFields.forEach(field => {
    if (result[field]) {
      const value = result[field] as string;
      const lowerValue = value.toLowerCase().trim();
      
      // Standardize percentage formatting
      const percentMatch = value.match(/(\d{1,3})\s*%/);
      if (percentMatch) {
        result[field] = `${percentMatch[1]}%`;
      }
      // Standardize QAR formatting
      else if (lowerValue.includes('qar') || /\d+/.test(lowerValue)) {
        const amountMatch = value.match(/(\d[\d,\.]*)/); 
        if (amountMatch) {
          const amount = amountMatch[1].replace(/\B(?=(\d{3})+(?!\d))/g, ",");
          if (!lowerValue.includes('qar')) {
            result[field] = `QAR ${amount}`;
          } else {
            // Ensure consistent spacing for QAR
            result[field] = value.replace(/QAR\s*(\d)/, 'QAR $1');
          }
        }
      }
    }
  });
  
  return result;
}

export async function extractDataApi({
  file,
  apiKey,
  fields,
  payerPlan,
  payerPlanName,
}: {
  file: File;
  apiKey: string;
  fields?: string[];
  payerPlan?: PayerPlan;
  payerPlanName?: string;
}): Promise<ExtractedData> {
  assertKey(apiKey);
  const startTime = Date.now();
  let success = false;
  let errorMessage = '';
  let extractedFields = 0;
console.log('fields', fields)
  try {
    // Log extraction started
    await logExtraction(file.name, 'started', `Starting extraction for ${payerPlanName || payerPlan || 'unknown'}`);
    console.log('in extractDataApi')
    
    // Track file upload start
    trackExtractionEvent('file_upload_started', {
      file_name: file.name,
      file_size: file.size,
      file_type: file.type,
      payer_plan: payerPlanName || 'unknown',
    });

    // STEP 1: Extract text from PDF using pdfjs-dist
    console.log('Step 1: Extracting text from PDF...');
    const pdfText = await extractTextFromPDF(file);
    console.log('PDF text extraction complete. Length:', pdfText.length);
    console.log('\n========== FULL PDF TEXT START ==========\n');
    console.log(pdfText);
    console.log('\n========== FULL PDF TEXT END ==========\n');

    // Track successful text extraction
    trackExtractionEvent('text_extraction_completed', {
      file_name: file.name,
      text_length: pdfText.length,
      payer_plan: payerPlanName || 'unknown',
    });

    // STEP 2: Resolve fields to extract
    const resolvedFields = (fields && fields.length > 0)
      ? fields
      : (payerPlan ? FIELD_MAPPINGS[payerPlan] : []);
    if (!resolvedFields || resolvedFields.length === 0) {
      throw new Error("No fields provided to extract.");
    }
console.log('resolvedFields',resolvedFields)
    // STEP 3: Extract fields directly from PDF text using OpenAI
    console.log('Step 2: Extracting fields from PDF text using OpenAI...');
    const json = await extractFieldsDirectly(pdfText, resolvedFields, apiKey, payerPlan, payerPlanName);
    // Log what was found for debugging
    console.log(`\n=== EXTRACTION DEBUG INFO ===`);
    console.log(`Payer Plan: ${payerPlan}`);
    console.log(`File: ${file.name} (${file.size} bytes)`);
    console.log(`Expected fields (${resolvedFields.length}):`, resolvedFields);
    console.log(`Extracted keys (${Object.keys(json).length}):`, Object.keys(json));
    console.log(`Raw extraction results:`, json);

    // Count extracted fields
    let foundFields = 0;
    
    // Ensure all expected keys exist; fill missing with null
    let normalized: ExtractedData = {};
    for (const key of resolvedFields) {
      const val = Object.prototype.hasOwnProperty.call(json, key) ? json[key] : null;
      normalized[key] = val === undefined ? null : (val as string | null);
      
      if (val !== null && val !== undefined) {
        foundFields++;
        console.log(`‚úì "${key}": ${typeof val === 'string' ? val.substring(0, 80) : val}${typeof val === 'string' && val.length > 80 ? '...' : ''}`);
      } else {
        console.log(`‚úó "${key}": NOT FOUND`);
      }
    }
    
    // Apply validation layer to catch hallucinations
    console.log(`\n=== VALIDATION LAYER ===`);
    normalized = validateAllExtractedData(normalized, resolvedFields);
    
    extractedFields = foundFields;
    
    // Track successful extraction
    success = true;
    trackExtractionEvent('extraction_completed', {
      file_name: file.name,
      file_size: file.size,
      payer_plan: payerPlanName || 'unknown',
      fields_expected: resolvedFields.length,
      fields_extracted: foundFields,
      extraction_time_ms: Date.now() - startTime,
      extraction_success_rate: (foundFields / resolvedFields.length) * 100,
    });

    // Plan-specific post-processing logic
    if (payerPlan === PAYER_PLANS.QLM) {
      normalized = formatQLMFields(normalized);
      console.log('Applied QLM-specific formatting');
    }

    // No fallback logic - return values as extracted from PDF only

    // Log final summary with detailed field status
    const foundCount = Object.values(normalized).filter(v => v !== null).length;
    const totalCount = resolvedFields.length;
    const successRate = ((foundCount / totalCount) * 100).toFixed(1);
    console.log(`\n=== FINAL EXTRACTION SUMMARY (After 3 Passes) ===`);
    console.log(`Fields found: ${foundCount}/${totalCount} (${successRate}%)`);
    console.log(`Payer Plan: ${payerPlan}`);
    console.log(`File: ${file.name}`);
    console.log(`Processing time: ${Date.now() - startTime}ms`);
    console.log(`\nField Status:`);
    
    // List all fields with their status
    const foundFieldsList = [];
    const missingFieldsList = [];
    for (const field of resolvedFields) {
      if (normalized[field] !== null) {
        foundFieldsList.push(field);
      } else {
        missingFieldsList.push(field);
      }
    }
    
    if (foundFieldsList.length > 0) {
      console.log(`\n‚úì FOUND (${foundFieldsList.length}):`);
      foundFieldsList.forEach(f => console.log(`  - ${f}`));
    }
    
    if (missingFieldsList.length > 0) {
      console.log(`\n‚úó MISSING (${missingFieldsList.length}):`);
      missingFieldsList.forEach(f => console.log(`  - ${f}`));
    }

    // Extra validation - force fix for Al Ahli Hospital issue
    // This is a last resort fix for the specific issue with Al Ahli field and inpatient co-insurance
    const ahliField = 'Provider-specific co-insurance at Al Ahli Hospital';
    const inpatientField = 'Co-insurance on all inpatient treatment';
    if (normalized[ahliField] && normalized[inpatientField] && 
        normalized[ahliField] === normalized[inpatientField] && 
        /^\d+%$/.test(normalized[ahliField] as string)) {
      console.log(`[CRITICAL FIX] Detected identical values for ${ahliField} (${normalized[ahliField]}) ` +
                  `and ${inpatientField} (${normalized[inpatientField]}) - fixing to 'Not applicable'`);
      normalized[ahliField] = 'Not applicable';
    }
    
    console.log(`Final extracted data:`, normalized);
    console.log(`=== END EXTRACTION ===
`);

    // Log successful extraction
    await logExtraction(file.name, 'success', `Extracted ${Object.values(normalized).filter(v => v !== null).length}/${totalCount} fields (${successRate}%)`);

    return normalized;
  } catch (error) {
    console.error("Extraction failed:", error);
    
    // Track extraction failure
    const errorMsg = error instanceof Error ? error.message : String(error);
    
    // Log extraction error
    await logExtraction(file.name, 'error', errorMsg);
    
    trackExtractionEvent('extraction_failed', {
      file_name: file.name,
      file_size: file.size,
      payer_plan: payerPlanName || 'unknown',
      error_message: errorMsg,
      extraction_time_ms: Date.now() - startTime,
    });
    
    throw error;
  } finally {
    // Track overall extraction attempt
    if (!success) {
      trackExtractionEvent('extraction_attempted', {
        file_name: file.name,
        file_size: file.size,
        payer_plan: payerPlanName || 'unknown',
        success: false,
        extraction_time_ms: Date.now() - startTime,
        error_message: errorMessage,
      });
    }
  }
}

interface CompareDataApiParams {
  file1: File;
  file2: File;
  apiKey: string;
  fields?: string[];
  payerPlan?: PayerPlan;
  payerPlanName?: string;
}
 
export async function compareDataApi({ 
  file1, 
  file2, 
  apiKey, 
  fields, 
  payerPlan, 
  payerPlanName 
}: CompareDataApiParams): Promise<ComparisonResult[]> {
  // Extract both in parallel
  const [data1, data2] = await Promise.all([
    extractDataApi({ file: file1, apiKey, fields, payerPlan, payerPlanName }),
    extractDataApi({ file: file2, apiKey, fields, payerPlan, payerPlanName }),
  ]);

  const resolvedFields = (fields && fields.length > 0)
    ? fields
    : (payerPlan ? FIELD_MAPPINGS[payerPlan] : Object.keys(data1));
  const results: ComparisonResult[] = resolvedFields.map((field) => {
    const v1 = (data1 as any)[field] ?? null;
    const v2 = (data2 as any)[field] ?? null;

    let status: ComparisonResult["status"] = "same";
    if (v1 === null && v2 === null) status = "missing";
    else if (v1 !== v2) status = "different";

    return { field, file1Value: v1, file2Value: v2, status };
  });

  return results;
}

/**
 * Public API to convert a PDF file to Markdown format
 * with specific formatting rules for headers, footers, and tables
 */
export async function convertPDFToMarkdownApi(
  file: File,
  apiKey: string
): Promise<string> {
  assertKey(apiKey);
  return convertPDFToMarkdown(file, apiKey);
}

